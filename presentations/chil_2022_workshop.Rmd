---
title: "Challenges in Developing Online Learning and Experimentation Algorithms in Digital Health (CHIL 2022)"
author: "Walter Dempsey"
date: "04/08/2022"
output:
  beamer_presentation: default
---

```{r setup, include = FALSE}
# library(reticulate)
# use_python("/usr/bin/python2.7")
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(kableExtra)
```

## AI 4 Mobile Health

- Digital Health and Micro-randomized trials (MRTs)
  + Use case: synthetic HeartSteps
- _Primary_ Analysis of MRT data
  + Causal inference
- MRTs with personalization
  + Reinforcement learning

## Mobile Health Interventions

- Pull intervention
  + Static content that can be accessed _whenever the user finds it necessary_
  + E.g., Mindfulness or guided meditation, exercise tips, low salt food alternative lookup
- Push intervention
  + App component that is _triggered by the system itself_
  + No need for user involvement
  + E.g., prompt to encourage self-monitoring, prompt to encorage physical activity, prompt to use the low salt alternative component.
  
## HeartSteps (PI Klasnja)

- Develop a mobile activity coach for individuals who are at risk of coronoary artery disease
- Include right combination of pull components with
- Push components _delivered at the right times_ to encourage activity throughout the day

## HeartSteps V1: Evening Planning

```{r eventplanning, echo=FALSE, fig.cap="Event Planning Example", out.width = '30%'}
knitr::include_graphics("figs/evening_planning_fig1.png")
```

## HeartSteps V1: Activity Suggestion

```{r activitysuggestion, echo=FALSE, fig.cap="Activity Suggestion Example", out.width = '30%'}
knitr::include_graphics("figs/activity_suggestion.png")
```

## Questions to improve the activity suggestions

- Do tailored activity suggestions have an effect at all?
- Does the effect of suggestions change over time? 
- When should we send suggestions for optimal effect?

## HeartSteps 

- 3 iterative studies

## Micro-randomized trial

- Micro-randomization = each user is randomized many times = sequential experimentation
- Randomization may use online predictions as well as reinforcement learning
- Probabilistic budgets on number of treatment pushes to manage treatment burden

## Data from wearable devices

- On each individual we observe the sequence
$$
(O_1, A_1, Y_2, O_2, A_2, Y_3, \ldots, O_t, A_t, Y_{t+1}, \ldots, O_T, A_T, Y_{T+1})
$$
- $t$: Decision point
- $O_t$: Observations at $t^{\text{th}}$ decision point
- $A_t$: treatment push at $t^{\text{th}}$ decision point
- $Y_{t+1}$: Proximal outcome (e.g., reward, utility, cost)

## Micro-randomized trial elements:

* Decision points, $t$ (Times at which an intervention can be provided)
  + Regular intervals in time (e.g., every 10 minutes)
  + At user demand
* **HeartSteps**: Approximately every 2-2.5 hours at user-specific times labeled as monring, mid-day, mid-afternoon, early evening, after dinner

## Micro-randomized trial elements:{.columns-2}

\begin{columns}
\begin{column}{0.48\textwidth}

\begin{itemize}
\item Treatments $A_t$:
\item Types of treatments that can be provided at a decision point, $t$
\item {\bf HeartSteps}: tailored activity suggestion (yes/no)

\end{itemize}

\end{column}
\begin{column}{0.48\textwidth}
```{r activityfig, echo=FALSE, fig.cap="Activity Suggestion Example", out.width = '75%'}
knitr::include_graphics("figs/act_suggestion_small.PNG")
```
\end{column}
\end{columns}


## Micro-randomized trial elements

* Randomization:
  + A stochastic strategy for selecting among the treatments at each decision point
  + The probabilistic distribution of $A_t$
* **HeartSteps**: push or do not push tailed suggestion
  - $P(A_t = 1) = 0.6$ (push)
  - $P(A_t = 0) = 0.4$ (do not push)

## Micro-randomized trial elements:

5. Proximal outcome: $Y_{t+1}$
  + Mediators that are thought to be critical to achieving a longer term clinical health outcome such as improved heart health
- __HeartSteps__ Activity (step count) over next 30 minutes
- Question: how can we use AI to determine the length of time over which the proximal outcome is measured?

## Availability

* Interventions, $A_t$, can only be delivered at a decision point if the decision point is _available_ for the user
  + $O_t$ includes $I_t = 1$ if available, and $I_t = 0$ if not
* Availability is known pre-decision point, i.e., pre-treatment
* Availability is not adherence, nor is it the same as interruptibility, receptivity

## Why Micro-randomization?

* Randomization (+ representative sample) is a gold standard in providing data to assess causal effects

* Sequential randomizations will enhance replicability of data analyses (decision rule development)


## Experimentation for continuous improvement

- "Iterative nature of experimentation" (RA Fisher & George Box)
- " At Google, experimentation is practically a mantra; we evaluate almost every change that potentially affects what our users experience." (4 Google scientists)
- "Online experiments are widely used to compare specific design alternatives, but they can also be used to produce generalizable knowledge and inform strategic decision making. Doing so often requires sophisticated experimental designs, iterative refinement, and careful logging and analysis" (3 Facebook scientists)

## Synthetic HeartSteps Data

- An MRT simulator based on Heartsteps V2 has been built in R and is available [here](https://drive.google.com/drive/folders/1rhCWugawTjEnwmagrOPwxNssrgIsnypT?usp=sharing)
- _ID_: Numeric id taking values between 1-110
- _Day_: Day-in-study (numeric)
- _Decision time_: Numeric indicator of indicator of decision time per day (1-5)
- _Dosage/burden_: Pre-defined function of past pushes (walking + anti-sedentary messages)
- _Engagement Indicator_: Binary indicator of whether the number of screens encountered in app from prior day from 12am to 11:59pm is greater than the 40% quantile of the screens collected.

## Synthetic HeartSteps Data

- _Temperature_: Temperature (In Celsius degree) at the current location
- _Location_: 1 if at a location other than home or work; 0 if at home or work (pre-specified)
- _Variation Indicator_: Indicator of higher recent variation in step counts than median long-term variation
- _Pre-treatment Steps_: Log-transformed steps 30 mins prior to the current decision time from the tracker; $\log(y+0.5)$.
- _Square root of steps yesterday_: The square root of step counts from the tracker collected from 12am to 11:59 pm

## Synthetic HeartSteps Data

```{r, echo = F}
HS_MRT_data = read.csv("data/HS_MRT_example_v2.csv")
knitr::kable(head(HS_MRT_data[1:5, 1:6]), format="simple",
             digits = rep(2,6), booktabs=TRUE)
```

## Synthetic HeartSteps Data

```{r, echo = F}
knitr::kable(head(HS_MRT_data[1:5, c(3,7:10)]), format="simple",
             digits = rep(2,6), booktabs=TRUE)
```

## Synthetic HeartSteps Data

```{r, echo = F}
knitr::kable(head(HS_MRT_data[1:5, c(3, 11:14)]), format="simple",
             digits = rep(2,6), booktabs=TRUE)
```

## Primary Analysis of MRT Data:

* Why consider conducting simple, interpretable, primary analyses?
  + In clinical and commercial settings
* Understand why causal excursion effects are useful for continual learning

## Heartsteps

* Goal: 

## Questions to Improve Synthetic HeartSteps Activity Suggestions

* Do tailored activity suggestions ahve an effect at all?
* Do less and more burdensome activity suggestions work equally well?
* Does the effect of suggestions change of time?
* When should we send suggestions for optimal effect?

## Micro-randomized trial

* How to justify the experimtntal trial costs in clinical research setting
  + Address a question that can be stated across disciplinary boundaries and be able to provide guarantees
  + Design trial so that a variety of further interesting questions can be answered
* **Large number of stakeholders with differing data needs/interests**

## Conceptual model: Primary analysis

* Data analysts want to fit a series of increasingly complex models:
* **Primary analysis**
$$
Y_{t+1} `\sim' \underbrace{\alpha_0 + \alpha_1^\top Z_t}_{\text{reduce noise}} + \underbrace{\beta_0 A_t}_{\text{causal main effect}}
$$
* $Z_t$: summary formed from $t$ and past/present observations
  + `Control Variables'
* $\beta_0$: is the effect, marginal over all observed and unobserved variables, of the activity suggestion on subsequent activity

## Conceptual model: Secondary analysis

* **Secondary analysis**
$$
Y_{t+1} `\sim' \underbrace{\alpha_0 + \alpha_1^\top Z_t}_{\text{reduce noise}} + \underbrace{\beta_0 A_t + \beta_1 A_t S_t}_{\text{causal moderation effect}}
$$
* $Z_t$: control variables
* $S_t$: potential moderator (e.g., current level of engagement)
* $\beta_0 + \beta_1$: is the effect when an individual is engaged ($S_t = 1$), marginal over all observed and unobserved variables, of the activity suggestion on subsequent activity.

## Scientific goal

* Analytic methods that are consistent with the scientific understanding of the meaning of $\beta$ coefficients
  + Make the scientist developing the intervention behavioral scientist
* Analytic methods that require minimal additional assumptions
  + Don't require strong modeling assumptions that may not hold
* Causal inference challenges:
  + Time-varying treatment $(A_t, t=1,\ldots,T)$
  + `Independent' variables: $Z_t, S_t, I_t$ all may be affected by prior treatment
* Robustly facilitate noise reduction via use of controls,~$Z_t$.

## Causal effects

* Use potential outcomes to define the effect
* The effects we define are *causal excursions*
  + Contrasts at a given time, averaging over prior randomizations
  + A 1-step excursion (send suggestion vs don't send suggestion) from the underlying stochastic policy.

## Potential outcomes

* $\bar A_t = (\bar A_1, \bar A_2,\ldots, \bar A_t)$
  + $\bar a_t$: realizations of treatments
* $Y_{t+1} (\bar a_{t-1})$ is the potential proximal outcome
* $I_{t+1} (\bar a_{t-1})$ is the potential *available for treatment* indicator
* $H_{t} (\bar a_{t-1})$ is the potential history vector
  + $S_t (\bar a_{t-1})$ is a vector of features from the potential history.

